{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import ehrapy as ep\n",
    "import anndata as ad\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Benchmark dataset creation\n",
    "# https://github.com/YerevaNN/mimic3-benchmarks\n",
    "#https://github.com/cmsalgado/book_chapter/blob/master/book_chapter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File or directory data.csv does not exist and no backup_url was provided.\nPlease provide a backup_url or check whether path is spelled correctly.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m--------------------------------------------\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m adata = \u001b[43mep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43micustay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m      2\u001b[39m adata.obs[\u001b[33m\"\u001b[39m\u001b[33mmortality_cat\u001b[39m\u001b[33m\"\u001b[39m] = adata[:, \u001b[33m\"\u001b[39m\u001b[33mmortality\u001b[39m\u001b[33m\"\u001b[39m].X\n",
      "\u001b[32m      3\u001b[39m adata.obs[\u001b[33m\"\u001b[39m\u001b[33mmortality_cat\u001b[39m\u001b[33m\"\u001b[39m] = adata.obs[\u001b[33m\"\u001b[39m\u001b[33mmortality_cat\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m).astype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shauna\\Documents\\MIMIC-FINAL\\.venv\\Lib\\site-packages\\ehrapy\\io\\_read.py:63\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(dataset_path, sep, index_column, columns_obs_only, columns_x_only, return_dfs, cache, download_dataset_name, backup_url, archive_format, **kwargs)\u001b[39m\n",
      "\u001b[32m     61\u001b[39m dataset_path = Path(dataset_path)\n",
      "\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_path.exists():\n",
      "\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     dataset_path = \u001b[43m_get_non_existing_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackup_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     65\u001b[39m adata = _read_csv(\n",
      "\u001b[32m     66\u001b[39m     file_path=dataset_path,\n",
      "\u001b[32m     67\u001b[39m     sep=sep,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     **kwargs,\n",
      "\u001b[32m     74\u001b[39m )\n",
      "\u001b[32m     75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m adata\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shauna\\Documents\\MIMIC-FINAL\\.venv\\Lib\\site-packages\\ehrapy\\io\\_read.py:476\u001b[39m, in \u001b[36m_get_non_existing_files\u001b[39m\u001b[34m(dataset_path, download_dataset_name, backup_url, archive_format)\u001b[39m\n",
      "\u001b[32m    470\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Handle non-existing files or directories by trying to download from a backup_url and moving them in the correct directory.\u001b[39;00m\n",
      "\u001b[32m    471\u001b[39m \n",
      "\u001b[32m    472\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n",
      "\u001b[32m    473\u001b[39m \u001b[33;03m    The file or directory path of the downloaded content.\u001b[39;00m\n",
      "\u001b[32m    474\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backup_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_path.exists():\n",
      "\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    477\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile or directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist and no backup_url was provided.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    478\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease provide a backup_url or check whether path is spelled correctly.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    479\u001b[39m     )\n",
      "\u001b[32m    480\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mPath or dataset does not yet exist. Attempting to download...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    481\u001b[39m download(\n",
      "\u001b[32m    482\u001b[39m     backup_url,\n",
      "\u001b[32m    483\u001b[39m     output_file_name=download_dataset_name,\n",
      "\u001b[32m    484\u001b[39m     output_path=ehrapy_settings.datasetdir,\n",
      "\u001b[32m    485\u001b[39m     archive_format=archive_format,\n",
      "\u001b[32m    486\u001b[39m )\n",
      "\n",
      "\u001b[31mValueError\u001b[39m: File or directory data.csv does not exist and no backup_url was provided.\n",
      "Please provide a backup_url or check whether path is spelled correctly."
     ]
    }
   ],
   "source": [
    "adata = ep.io.read_csv(\"data.csv\", index_column=\"icustay\")\n",
    "adata.obs[\"mortality_cat\"] = adata[:, \"mortality\"].X\n",
    "adata.obs[\"mortality_cat\"] = adata.obs[\"mortality_cat\"].astype(int).astype(str)\n",
    "adata.obs[\"icustay\"] = adata.obs.index.astype(int)\n",
    "adata"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
